{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c104c0-980e-4d6a-9cb5-19ab8eba943b",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Una red neuronal artificial (RNA) preentrenada es un modelo que ha sido entrenado previamente y luego distribuído (incluyendo arquitectura y valores de pesos) para su uso posterior. De esta manera no es necesario que volver a entrenarlo, o bien, se puede utilizar parte de el ya entrenado, y entrenar otras partes, realizando un ajuste fino o fine tuning. Constituye una manera de reducir los recursos y tiempos necesarios para generar un sistema de aprendizaje automático.\n",
    "\n",
    "Hugging Face es una plataforma de aprendizaje automático, conocida por su librería de [Transformers](https://es.wikipedia.org/wiki/Transformador(modelo_de_aprendizajeautom%C3%A1tico)) creada para aplicaciones de procesamiento de lenguaje natural y que permite a los usuarios compartir conjuntos de datos y modelos de aprendizaje automático preentrenados. Su Model Hub contiene miles de modelos previamente entrenados de código abierto que cualquiera puede descargar y usar. Además dispone de varios cursos en los que se enseñan conceptos de aprendizaje automático a la vez que como utilizar sus herramientas.\n",
    "\n",
    "Una de las formas más básicas de usar para inferencia la librería Hugging Face Transformers es la función pipeline(), que permite conectar uno de sus modelos de con los pasos necesarios para su preprocesamiento y posprocesamiento, abstrayendo la mayor parte del código complejo de la librería y ofreciendo una API simple dedicada a varias tareas, entre ellas, audio, visión artificial, procesamiento de lenguaje natural y tareas multimodales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8aec322-7373-43ef-aa7e-ec29986c4b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:54:49.552576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-09 08:54:49.552609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-09 08:54:49.553566: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 08:54:49.558807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-09 08:54:50.110308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Avoid some warning\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3b589-6127-4d4a-a512-3db66c226ffd",
   "metadata": {},
   "source": [
    "## Análisis de sentimientos\n",
    "El análisis de sentimientos premite clasificar textos de acuerdo a distintas etiquetas predeterminadas, como podrían ser textos positivos frente a negativos. Existen disintos modelos preentrenados disponibles para ello y para distintos idiomas, por ejemplo Spanish Sentiment Analysis Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042f8df5-49eb-4f21-a49f-7fedc97d27af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d63040e2c724a7893e9b5a6ca5595d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/785 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1c7723a67d449299ab789e8793e6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb4289ba7dd435788664a51ed47bb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb57a5d44944219b41662188d6bfa20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369c5a3a82db49c89ee2e69fbfbc7ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Positive', 'score': 0.9995808005332947}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allocate a piepeline for spanish sentiment-analysis\n",
    "classifier = pipeline(model='VerificadoProfesional/SaBERT-Spanish-Sentiment-Analysis')\n",
    "text_1 = \"Nos alegra introducirles las redes neuronales artificiales preentrenadas a ustedes.\"\n",
    "classifier(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b759b1-b264-4f3b-b242-1d8650036a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.9994773268699646}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2 = \"Sería una lástima que el tema no les resultara interesante.\"\n",
    "classifier(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b1ded3-0c3b-4c8c-9b45-22bd2a36c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Showing the classifier model\n",
    "print(classifier.model)\n",
    "# classifier.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e19b0-19ae-4c38-bedf-5ae1f30a2002",
   "metadata": {},
   "source": [
    "... o también podemos realizar puntuaciones sobre los textos usando nlptown/bert-base-multilingual-uncased-sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac358c18-ff73-49bf-852d-1a19ae7b324b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5192744c874463af753820d5c23e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438afb0c3d61449d9b22e6748cd8d0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9912893f4d4520b4f4b6f2941a8521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ab7c04e5f74dbfb6ae7d9add882b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94a745e1c2b44568072fd98b5e2d7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '3 stars', 'score': 0.2429007887840271}]\n",
      "[{'label': '2 stars', 'score': 0.44524437189102173}]\n"
     ]
    }
   ],
   "source": [
    "# Ranking texts\n",
    "classifier = pipeline(model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "print(classifier(text_1))\n",
    "print(classifier(text_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478f4a2-65ac-4f57-9d72-56e79b0d797a",
   "metadata": {},
   "source": [
    "Podemos traducir los textos a inglés mediante Helsinki-NLP/opus-mt-es-en y realizar las puntuaciones nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e81a65-997b-4c0f-8665-4d6f88bf3a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f140cf68bb4e1eb7bb4c0c9e53a125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b969bfd7c8494ed7b94316e10b433e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7c6e0812d542dfb5cf91e462a2d19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c08e43d0a04a8e8459a02fbe55ad48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221c759a5e3e410aa62ead48f6916980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e85333d759741c68c190b0b33c701ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dc52bc11a14fd29c98b5335ca96f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're glad to introduce the artificial neural networks pre-trained to you. [{'label': '5 stars', 'score': 0.580280065536499}]\n",
      "It would be a shame if they didn't find the subject interesting. [{'label': '3 stars', 'score': 0.3762303590774536}]\n"
     ]
    }
   ],
   "source": [
    "# Translate the texts\n",
    "translator = pipeline(model='Helsinki-NLP/opus-mt-es-en')\n",
    "text_1_translated = translator(text_1)[0]['translation_text']\n",
    "text_2_translated = translator(text_2)[0]['translation_text']\n",
    "\n",
    "# And rank again\n",
    "print(text_1_translated, classifier(text_1_translated))\n",
    "print(text_2_translated, classifier(text_2_translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8542d7-0ed6-4169-9768-3b6d060ab979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "\n",
    "# Reiniciando kernel para limpiar la memoria de la GPU\n",
    "!pkill -9 -f ipykernel_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebb28a-afd8-4f1c-8544-86b511856b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
